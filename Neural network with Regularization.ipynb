{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2a Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return  1/(1+np.exp(-z))\n",
    "\n",
    "def build_model(X,input_dim,hidden_nodes,output_dim):\n",
    "    model = {}\n",
    "    model['W1'] =  np.random.randn(input_dim, hidden_nodes) / np.sqrt(input_dim) \n",
    "    model['b1'] =  np.random.randn(1, hidden_nodes)\n",
    "    model['W2'] = np.random.randn(hidden_nodes, output_dim) / np.sqrt(hidden_nodes)\n",
    "    model['b2'] =  np.random.randn(1, output_dim)\n",
    "    return model\n",
    "\n",
    "def feed_forward(model, x):\n",
    "    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n",
    "    # Forward propagation layer 2 \n",
    "    z2 = x.dot(W1) + b1\n",
    "    a2 = sigmoid(z2)\n",
    "    #print(\"z2:\",z2)\n",
    "    # Forward propagation layer 3 \n",
    "    z3 = a2.dot(W2) + b2\n",
    "    a3 = sigmoid(z3)\n",
    "    #print(\"z3:\",z3)\n",
    "    return a2,a3\n",
    "\n",
    "def backprop(x,y,model,a2,a3,dW1,db1,dW2,db2):\n",
    "    #layer 3 error do\n",
    "    del3 = a3 - y\n",
    "    #print(\"del3:\",del3)\n",
    "    db2 += np.sum(del3, axis=0, keepdims=True)\n",
    "    dW2 += (a2.T).dot(del3)\n",
    "    #print(\"db2:\",db2)\n",
    "    #print(\"dW2:\",dW2)\n",
    "    #layer 2 error do \n",
    "         \n",
    "    del2 = np.multiply(del3.dot(model['W2'].T),(a2*(1-a2)))\n",
    "    #print(\"del2:\",del2)\n",
    "    db1 += np.sum(del2, axis=0)\n",
    "    dW1 += np.dot(x.T, del2)\n",
    "    \n",
    "    #print(\"db1:\",db1)\n",
    "    #print(\"dW1:\",dW1)\n",
    "    # Add regularization terms\n",
    "    #dW2 += reg_lambda * model['W2']\n",
    "    #dW1 += reg_lambda * model['W1']\n",
    "    \n",
    "    return dW1, dW2, db1, db2\n",
    "\n",
    "\n",
    "def calculate_loss(N,model,a3,y_true,sum_cost):\n",
    "    \n",
    "    sum_cost +=np.sum((y_true*np.log(a3))+((1-y_true)*np.log(1-a3)))\n",
    "    #print(\"sum_cost\",sum_cost)\n",
    "    return sum_cost\n",
    "\n",
    "def train(N,model, X_train, y_train, reg_lambda, learning_rate,hidden_nodes):\n",
    "    # Batch gradient descent\n",
    "    done = False\n",
    "    previous_loss = float('inf')\n",
    "    i = 0\n",
    "    \n",
    "    losses = []\n",
    "    #while done == False:  #comment out while performance testing\n",
    "    while i < 500:\n",
    "        scost=0\n",
    "        dW1 =np.random.randn(input_dim, hidden_nodes) / np.sqrt(input_dim) \n",
    "        db1 = np.random.randn(1, hidden_nodes)\n",
    "        dW2 = np.random.randn(hidden_nodes, output_dim) / np.sqrt(hidden_nodes)\n",
    "        db2 = np.random.randn(1, output_dim)\n",
    "        \n",
    "        for row in zip(X_train, y_train):\n",
    "            #feed forward\n",
    "            #print(\"shape\",row[0].shape,\"y shape\", row[1].shape,row[0][None,:].shape,row[1][None,:])\n",
    "            a2,a3 = feed_forward(model, row[0][None,:])\n",
    "            #print(\"model\",model)\n",
    "            #print(\"a2:\",a2,\"a3:\",a3)\n",
    "            \n",
    "            #Backward propagation\n",
    "            #print(\"for back prop:\",row[0][None,:],row[1][None,:])\n",
    "            dW1, dW2, db1, db2 = backprop(row[0][None,:],row[1][None,:],model,a2,a3,dW1,db1,dW2,db2)\n",
    "            #print(\"dW1\",dW1,\"dW2\",\"db1\",db1,\"db2\",db2)\n",
    "            \n",
    "            #cost\n",
    "            cost = calculate_loss(N,model, a3,row[1][None,:], scost)\n",
    "            #print(\"cost:\",cost)\n",
    "        #update weights and biases\n",
    "        model['W1'] -= learning_rate* ((dW1/N) + (reg_lambda/N)*model['W1'])\n",
    "        model['b1'] -= learning_rate*(db1/N)\n",
    "        model['W2'] -= learning_rate* ((dW2/N) + (reg_lambda/N)*model['W2'])\n",
    "        model['b2'] -= learning_rate*(db2/N)\n",
    "            \n",
    "        \n",
    "        loss = (-1/N)*cost + ((reg_lambda/(2*N)) * (np.sum(np.square(model['W1'])) + np.sum(np.square(model['W2']))))\n",
    "        \n",
    "        losses.append(loss)\n",
    "        if i%100==0:\n",
    "            print (\"Loss after iteration %i: %f\" %(i, loss))  #uncomment once testing finished, return mod val to 1000\n",
    "        #if (previous_loss-loss) < 0.001:\n",
    "            #done = True\n",
    "            #print(\"convergence i:\",i) \n",
    "            #break\n",
    "        previous_loss = loss\n",
    "        i += 1\n",
    "    return model, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdataset = pd.read_csv('BSOM_DataSet_for_HW3.csv')\n",
    "X = sdataset.loc[:,['all_mcqs_avg_n20','all_NBME_avg_n4','CBSE_01','CBSE_02']].values\n",
    "y = sdataset.loc[:,['LEVEL']].values\n",
    "\n",
    "#Feature Scaling using Mean normalization \n",
    "mean_norm_X = (X-np.mean(X,axis=0))/(np.max(X,axis=0)-np.min(X,axis=0))\n",
    "#One vs all y_train\n",
    "concat=[]\n",
    "for i in np.unique(y):\n",
    "    one_vs_all_y=np.where(y==i,1,0)\n",
    "    concat.extend(list(zip(*one_vs_all_y)))\n",
    "actual_y= np.asarray(concat).T \n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(mean_norm_X, actual_y, test_size = 1/3)\n",
    "\n",
    "N,input_dim = X_train.shape \n",
    "# output layer dimensionality \n",
    "output_dim = len(np.unique(y)) \n",
    "# learning rate for gradient descent\n",
    "learning_rate = 0.6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fscore(y_true, y_pred):\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')  \n",
    "    print(\"F1 macro :\" ,f1_macro)\n",
    "    f1_micro  = f1_score(y_test, y_pred, average='micro')  \n",
    "    print(\"F1 micro :\" ,f1_micro)\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')  \n",
    "    print(\"F1 weighted :\" ,f1_weighted)\n",
    "    f1 = f1_score(y_test, y_pred, average=None)\n",
    "    print(\"F1 score :\" ,f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2c metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization for lambda : 0\n",
      "Loss after iteration 0: 0.067144\n",
      "Loss after iteration 100: 0.025122\n",
      "Loss after iteration 200: 0.021390\n",
      "Loss after iteration 300: 0.020507\n",
      "Loss after iteration 400: 0.020797\n",
      "y_true [1, 0, 1, 1, 3, 2, 1, 0, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 1, 0, 2, 1, 0, 1, 0, 1, 0, 0, 1, 2, 1]\n",
      "y_pred [0, 0, 0, 1, 2, 2, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 0, 0, 0, 2, 1, 0, 2, 2, 0, 1, 0, 1, 1, 0, 2, 2, 1]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.75      0.90      0.82        10\n",
      "          B       0.82      0.45      0.58        20\n",
      "          C       0.38      0.86      0.52         7\n",
      "          D       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.68      0.62      0.60        39\n",
      "\n",
      "confusion matrix: [[9 1 0 0]\n",
      " [3 9 8 0]\n",
      " [0 1 6 0]\n",
      " [0 0 2 0]]\n",
      "Accuracy: 0.6153846153846154\n",
      "F1 macro : 0.48014152747673083\n",
      "F1 micro : 0.6153846153846154\n",
      "F1 weighted : 0.6012024441196951\n",
      "F1 score : [0.81818182 0.58064516 0.52173913 0.        ]\n",
      "ROC AUC score 0.7107414279232565\n",
      "Regularization for lambda : 0.001\n",
      "Loss after iteration 0: 0.070311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 100: 0.025169\n",
      "Loss after iteration 200: 0.021872\n",
      "Loss after iteration 300: 0.021464\n",
      "Loss after iteration 400: 0.021843\n",
      "y_true [1, 0, 1, 1, 3, 2, 1, 0, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 1, 0, 2, 1, 0, 1, 0, 1, 0, 0, 1, 2, 1]\n",
      "y_pred [0, 0, 0, 1, 2, 2, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 0, 0, 0, 2, 1, 0, 2, 2, 0, 1, 0, 1, 1, 0, 2, 2, 1]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.75      0.90      0.82        10\n",
      "          B       0.82      0.45      0.58        20\n",
      "          C       0.38      0.86      0.52         7\n",
      "          D       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.68      0.62      0.60        39\n",
      "\n",
      "confusion matrix: [[9 1 0 0]\n",
      " [3 9 8 0]\n",
      " [0 1 6 0]\n",
      " [0 0 2 0]]\n",
      "Accuracy: 0.6153846153846154\n",
      "F1 macro : 0.48014152747673083\n",
      "F1 micro : 0.6153846153846154\n",
      "F1 weighted : 0.6012024441196951\n",
      "F1 score : [0.81818182 0.58064516 0.52173913 0.        ]\n",
      "ROC AUC score 0.7107414279232565\n",
      "Regularization for lambda : 0.01\n",
      "Loss after iteration 0: 0.050227\n",
      "Loss after iteration 100: 0.025546\n",
      "Loss after iteration 200: 0.025441\n",
      "Loss after iteration 300: 0.027472\n",
      "Loss after iteration 400: 0.029222\n",
      "y_true [1, 0, 1, 1, 3, 2, 1, 0, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 1, 0, 2, 1, 0, 1, 0, 1, 0, 0, 1, 2, 1]\n",
      "y_pred [0, 0, 0, 1, 1, 2, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 0, 0, 0, 2, 1, 0, 2, 2, 0, 1, 0, 1, 1, 0, 2, 2, 1]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.75      0.90      0.82        10\n",
      "          B       0.75      0.45      0.56        20\n",
      "          C       0.40      0.86      0.55         7\n",
      "          D       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.65      0.62      0.60        39\n",
      "\n",
      "confusion matrix: [[9 1 0 0]\n",
      " [3 9 8 0]\n",
      " [0 1 6 0]\n",
      " [0 1 1 0]]\n",
      "Accuracy: 0.6153846153846154\n",
      "F1 macro : 0.48153409090909094\n",
      "F1 micro : 0.6153846153846154\n",
      "F1 weighted : 0.5961538461538463\n",
      "F1 score : [0.81818182 0.5625     0.54545455 0.        ]\n",
      "ROC AUC score 0.7080687305548353\n",
      "Regularization for lambda : 0.1\n",
      "Loss after iteration 0: 0.050259\n",
      "Loss after iteration 100: 0.041666\n",
      "Loss after iteration 200: 0.063979\n",
      "Loss after iteration 300: 0.078544\n",
      "Loss after iteration 400: 0.089927\n",
      "y_true [1, 0, 1, 1, 3, 2, 1, 0, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 1, 0, 2, 1, 0, 1, 0, 1, 0, 0, 1, 2, 1]\n",
      "y_pred [0, 0, 0, 1, 2, 2, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 0, 0, 0, 2, 1, 0, 2, 2, 0, 1, 0, 1, 1, 0, 2, 2, 1]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.75      0.90      0.82        10\n",
      "          B       0.82      0.45      0.58        20\n",
      "          C       0.38      0.86      0.52         7\n",
      "          D       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.68      0.62      0.60        39\n",
      "\n",
      "confusion matrix: [[9 1 0 0]\n",
      " [3 9 8 0]\n",
      " [0 1 6 0]\n",
      " [0 0 2 0]]\n",
      "Accuracy: 0.6153846153846154\n",
      "F1 macro : 0.48014152747673083\n",
      "F1 micro : 0.6153846153846154\n",
      "F1 weighted : 0.6012024441196951\n",
      "F1 score : [0.81818182 0.58064516 0.52173913 0.        ]\n",
      "ROC AUC score 0.7107414279232565\n",
      "Regularization for lambda : 0.2\n",
      "Loss after iteration 0: 0.039179\n",
      "Loss after iteration 100: 0.065432\n",
      "Loss after iteration 200: 0.104956\n",
      "Loss after iteration 300: 0.129747\n",
      "Loss after iteration 400: 0.143889\n",
      "y_true [1, 0, 1, 1, 3, 2, 1, 0, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 1, 0, 2, 1, 0, 1, 0, 1, 0, 0, 1, 2, 1]\n",
      "y_pred [0, 0, 0, 1, 2, 2, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 0, 0, 0, 2, 1, 0, 2, 2, 0, 1, 0, 1, 1, 0, 2, 2, 0]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.69      0.90      0.78        10\n",
      "          B       0.80      0.40      0.53        20\n",
      "          C       0.38      0.86      0.52         7\n",
      "          D       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.66      0.59      0.57        39\n",
      "\n",
      "confusion matrix: [[9 1 0 0]\n",
      " [4 8 8 0]\n",
      " [0 1 6 0]\n",
      " [0 0 2 0]]\n",
      "Accuracy: 0.5897435897435898\n",
      "F1 macro : 0.4594202898550724\n",
      "F1 micro : 0.5897435897435898\n",
      "F1 weighted : 0.5678186547751765\n",
      "F1 score : [0.7826087  0.53333333 0.52173913 0.        ]\n",
      "ROC AUC score 0.7001810830956702\n",
      "Regularization for lambda : 0.4\n",
      "Loss after iteration 0: 0.052802\n",
      "Loss after iteration 100: 0.078224\n",
      "Loss after iteration 200: 0.144161\n",
      "Loss after iteration 300: 0.177337\n",
      "Loss after iteration 400: 0.190562\n",
      "y_true [1, 0, 1, 1, 3, 2, 1, 0, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 1, 0, 2, 1, 0, 1, 0, 1, 0, 0, 1, 2, 1]\n",
      "y_pred [0, 0, 0, 1, 2, 2, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 0, 0, 0, 2, 1, 0, 2, 2, 0, 1, 0, 1, 1, 0, 2, 2, 0]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.69      0.90      0.78        10\n",
      "          B       0.80      0.40      0.53        20\n",
      "          C       0.38      0.86      0.52         7\n",
      "          D       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.66      0.59      0.57        39\n",
      "\n",
      "confusion matrix: [[9 1 0 0]\n",
      " [4 8 8 0]\n",
      " [0 1 6 0]\n",
      " [0 0 2 0]]\n",
      "Accuracy: 0.5897435897435898\n",
      "F1 macro : 0.4594202898550724\n",
      "F1 micro : 0.5897435897435898\n",
      "F1 weighted : 0.5678186547751765\n",
      "F1 score : [0.7826087  0.53333333 0.52173913 0.        ]\n",
      "ROC AUC score 0.7001810830956702\n"
     ]
    }
   ],
   "source": [
    "hidden_nodes= 5\n",
    "rlambda = [0,0.001,0.01,0.1,0.2,0.4] \n",
    "for reg_lambda in rlambda:\n",
    "    print(\"Regularization for lambda :\",reg_lambda)\n",
    "    model2 = build_model(X_train,input_dim,hidden_nodes,output_dim)\n",
    "    model2, losses2 = train(N,model2,X_train, y_train, reg_lambda, learning_rate,hidden_nodes)\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for row in zip(X_test, y_test):\n",
    "        a2, a3 = feed_forward(model2, row[0][None,:])\n",
    "        y_pred.append(np.argmax(a3))\n",
    "        y_true.append(np.argmax(row[1][None,:]))\n",
    "    print(\"y_true\",y_true)\n",
    "    print(\"y_pred\",y_pred)\n",
    "    print(classification_report(y_true, y_pred,target_names=['A', 'B', 'C','D']))   \n",
    "    print(\"confusion matrix:\",confusion_matrix(y_true, y_pred))\n",
    "    print(\"Accuracy:\",accuracy_score(y_true, y_pred))\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_true)\n",
    "    y_t= lb.transform(y_true)\n",
    "    y_p = lb.transform(y_pred)\n",
    "    fscore(y_t,y_p)\n",
    "    print(\"ROC AUC score\",metrics.roc_auc_score(y_t,y_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2b and 2c metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0: 0.171504\n",
      "Loss after iteration 100: 0.023559\n",
      "Loss after iteration 200: 0.020968\n",
      "Loss after iteration 300: 0.020687\n",
      "Loss after iteration 400: 0.020962\n",
      "y_true [1, 0, 1, 1, 3, 2, 1, 0, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 0, 0, 2, 1, 0, 2, 1, 0, 1, 0, 1, 0, 0, 1, 2, 1]\n",
      "y_pred [0, 0, 0, 1, 2, 2, 0, 0, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 0, 0, 0, 2, 1, 0, 2, 2, 0, 1, 0, 1, 1, 0, 2, 2, 0]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.69      0.90      0.78        10\n",
      "          B       0.80      0.40      0.53        20\n",
      "          C       0.38      0.86      0.52         7\n",
      "          D       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.66      0.59      0.57        39\n",
      "\n",
      "confusion matrix: [[9 1 0 0]\n",
      " [4 8 8 0]\n",
      " [0 1 6 0]\n",
      " [0 0 2 0]]\n",
      "Accuracy: 0.5897435897435898\n",
      "F1 macro : 0.47669915042478755\n",
      "F1 micro : 0.6153846153846154\n",
      "F1 weighted : 0.590256153974295\n",
      "F1 score : [0.83333333 0.55172414 0.52173913 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def build_model_sametheta(X,input_dim,hidden_nodes,output_dim):\n",
    "    model = {}\n",
    "    model['W1'] =  np.ones((input_dim, hidden_nodes))\n",
    "    model['b1'] =  np.ones((1, hidden_nodes))\n",
    "    model['W2'] = np.ones((hidden_nodes, output_dim))\n",
    "    model['b2'] =  np.ones((1, output_dim))\n",
    "    return model\n",
    "hidden_nodes= 5\n",
    "reg_lambda = 0.001\n",
    "\n",
    "model2 = build_model_sametheta(X_train,input_dim,hidden_nodes,output_dim)\n",
    "model2, losses2 = train(N,model2,X_train, y_train, reg_lambda, learning_rate,hidden_nodes)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for row in zip(X_test, y_test):\n",
    "    a2, a3 = feed_forward(model2, row[0][None,:])\n",
    "    y_pred.append(np.argmax(a3))\n",
    "    y_true.append(np.argmax(row[1][None,:]))\n",
    "print(\"y_true\",y_true)\n",
    "print(\"y_pred\",y_pred)\n",
    "print(classification_report(y_true, y_pred,target_names=['A', 'B', 'C','D']))   \n",
    "print(\"confusion matrix:\",confusion_matrix(y_true, y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_true, y_pred))\n",
    "fscore(y_t,y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
