{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Correlation between Target and Features using Spearman correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearsoncorr(X, Y):\n",
    "    covar = np.mean(Y*X)-(np.mean(Y)*np.mean(X))\n",
    "    stddev_1 = np.sqrt(np.mean(Y**2)-(np.mean(Y))**2)\n",
    "    stddev_2 = np.sqrt(np.mean(X**2)-np.mean(X)**2)\n",
    "    corr_coeff = covar/(stddev_1*stddev_2)\n",
    "    print(\"Pearson Correlation Coefficient:\",corr_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdataset = pd.read_csv('BSOM_DataSet_for_HW3.csv')\n",
    "Xmcqs = sdataset.loc[:,['all_mcqs_avg_n20']].values\n",
    "Xnbme = sdataset.loc[:,['all_NBME_avg_n4']].values\n",
    "Xcbse1 = sdataset.loc[:,['CBSE_01']].values\n",
    "Xcbse2 = sdataset.loc[:,['CBSE_02']].values\n",
    "Xstep1 = sdataset.loc[:,['STEP_1']].values\n",
    "XHA_final = sdataset.loc[:,['HA_final']].values\n",
    "XHA_PI_AVG = sdataset.loc[:,['HA_PI_AVG_04']].values\n",
    "XB2ENBME = sdataset.loc[:,['B2E_NBME_final']].values\n",
    "XHDPIAVG = sdataset.loc[:,['HD_PI_AVG_15']].values\n",
    "XHDIRATAVG = sdataset.loc[:,['HD_IRAT_AVG_02']].values\n",
    "XBCRPIAVG = sdataset.loc[:,['BCR_PI_AVG_30']].values\n",
    "XSAIRATAVG =sdataset.loc[:,['SA_IRAT_AVG_07']].values\n",
    "XB2EIRATAVG =sdataset.loc[:,['B2E_IRAT_AVG_06']].values\n",
    "XBCRIRATAVG =sdataset.loc[:,['BCR_IRAT_AVG_03']].values\n",
    "XBCRANATMCQAVG =sdataset.loc[:,['BCR_ANAT_MCQ_AVG_02']].values\n",
    "#target\n",
    "yy = sdataset.loc[:,['LEVEL']]\n",
    "level = {'A': 0,'B': 1,'C':2,'D':3} \n",
    "y_copy = [level[item] for item in yy.LEVEL]\n",
    "y_copy = np.asarray(y_copy)\n",
    "target = y_copy[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B/w target and HA_final:\n",
      "SpearmanrResult(correlation=-0.46080943853350176, pvalue=2.1920581800321847e-07)\n",
      "B/w target and step1\n",
      "SpearmanrResult(correlation=-0.9412166544561835, pvalue=4.3582758063370176e-55)\n",
      "B/w target and HAPIAVG\n",
      "SpearmanrResult(correlation=-0.5172336574189177, pvalue=3.2475926121345915e-09)\n",
      "B/w target and HDPIAVG\n",
      "SpearmanrResult(correlation=-0.4901745276275143, pvalue=2.692016513883656e-08)\n",
      "B/w target and XHDIRATAVG\n",
      "SpearmanrResult(correlation=-0.3854009849505833, pvalue=2.106208033370216e-05)\n",
      "B/w target and BCRPIAVG\n",
      "SpearmanrResult(correlation=-0.5502290320965951, pvalue=1.892219091055297e-10)\n",
      "B/w target and SAIRATAVG\n",
      "SpearmanrResult(correlation=-0.5120986507360566, pvalue=4.9212014925915955e-09)\n",
      "B/w target and XB2EIRATAVG\n",
      "SpearmanrResult(correlation=-0.47226661490308897, pvalue=9.899515947883915e-08)\n",
      "B/w target and XBCRANATMCQAVG\n",
      "SpearmanrResult(correlation=-0.46564809726961476, pvalue=1.57248012152044e-07)\n"
     ]
    }
   ],
   "source": [
    "print(\"B/w target and HA_final:\")\n",
    "print(spearmanr(target,XHA_final))\n",
    "print(\"B/w target and step1\")\n",
    "print(spearmanr(target,Xstep1))\n",
    "print(\"B/w target and HAPIAVG\")\n",
    "print(spearmanr(target,XHA_PI_AVG))\n",
    "\n",
    "print(\"B/w target and HDPIAVG\")\n",
    "print(spearmanr(target,XHDPIAVG))\n",
    "print(\"B/w target and XHDIRATAVG\")\n",
    "print(spearmanr(target,XHDIRATAVG))\n",
    "print(\"B/w target and BCRPIAVG\")\n",
    "print(spearmanr(target,XBCRPIAVG))\n",
    "print(\"B/w target and SAIRATAVG\")\n",
    "print(spearmanr(target,XSAIRATAVG))\n",
    "print(\"B/w target and XB2EIRATAVG\")\n",
    "print(spearmanr(target,XB2EIRATAVG))\n",
    "\n",
    "print(\"B/w target and XBCRANATMCQAVG\")\n",
    "print(spearmanr(target,XBCRANATMCQAVG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Correlation between Features using Pearson correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B/w mcqs and step1\n",
      "Pearson Correlation Coefficient: 0.7027184782873007\n",
      "B/w cbse and BCRPIAVG\n",
      "Pearson Correlation Coefficient: 0.5721730984151181\n",
      "B/w Xmcqs and BCRPIAVG\n",
      "Pearson Correlation Coefficient: 0.8278558574743187\n",
      "B/w cbse and XSAIRATAVG\n",
      "Pearson Correlation Coefficient: 0.5476270395001492\n",
      "B/w mcqs and HAPIAVG\n",
      "Pearson Correlation Coefficient: 0.7087295432282957\n",
      "Pearson Correlation Coefficient: 0.4495872358856143\n",
      "B/w nbme and HDPIAVG\n",
      "Pearson Correlation Coefficient: 0.7630822593495324\n",
      "B/w step1 and cbse1\n",
      "Pearson Correlation Coefficient: 0.5316958279960595\n",
      "B/w nbme and XHDIRATAVG\n",
      "Pearson Correlation Coefficient: 0.7630822593495324\n",
      "B/w nbme and XHDIRATAVG\n",
      "Pearson Correlation Coefficient: 0.7630822593495324\n",
      "B/w cbse and XB2EIRATAVG\n",
      "Pearson Correlation Coefficient: 0.44020939336032605\n",
      "B/w cbse and XBCRANATMCQAVG\n",
      "Pearson Correlation Coefficient: 0.4598059186444644\n",
      "B/w mcqs and HA_final:\n",
      "Pearson Correlation Coefficient: 0.665277846332941\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"B/w mcqs and step1\")\n",
    "pearsoncorr(Xmcqs,Xstep1)\n",
    "print(\"B/w cbse and BCRPIAVG\")\n",
    "pearsoncorr(Xcbse1,XBCRPIAVG)\n",
    "print(\"B/w Xmcqs and BCRPIAVG\")\n",
    "pearsoncorr(Xmcqs,XBCRPIAVG)\n",
    "print(\"B/w cbse and XSAIRATAVG\")\n",
    "pearsoncorr(Xcbse1,XSAIRATAVG)\n",
    "\n",
    "print(\"B/w mcqs and HAPIAVG\")\n",
    "pearsoncorr(Xmcqs,XHA_PI_AVG)\n",
    "pearsoncorr(Xnbme,XHDIRATAVG)\n",
    "print(\"B/w nbme and HDPIAVG\")\n",
    "pearsoncorr(Xnbme,XHDPIAVG)\n",
    "print(\"B/w step1 and cbse1\")\n",
    "pearsoncorr(Xcbse1,Xstep1)\n",
    "print(\"B/w nbme and XHDIRATAVG\")\n",
    "pearsoncorr(Xnbme,XHDPIAVG)\n",
    "print(\"B/w nbme and XHDIRATAVG\")\n",
    "pearsoncorr(Xnbme,XHDPIAVG)\n",
    "print(\"B/w cbse and XB2EIRATAVG\")\n",
    "pearsoncorr(Xcbse1,XB2EIRATAVG)\n",
    "print(\"B/w cbse and XBCRANATMCQAVG\")\n",
    "pearsoncorr(Xcbse1,XBCRANATMCQAVG)\n",
    "\n",
    "print(\"B/w mcqs and HA_final:\")\n",
    "pearsoncorr(Xmcqs,XHA_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return  1/(1+np.exp(-z))\n",
    "\n",
    "def build_model(X,neural_layer,input_dim,hidden_nodes,output_dim):\n",
    "    model = {}\n",
    "    for i in range(neural_layer):\n",
    "        if i==0:\n",
    "            continue\n",
    "        elif i==1:\n",
    "            #print(\"1st elif loop\",i)\n",
    "            model['W'+str(i)] =  np.random.randn(input_dim, hidden_nodes) / np.sqrt(input_dim) \n",
    "            model['b'+str(i)] =  np.zeros((1, hidden_nodes))\n",
    "        elif i==neural_layer-1:\n",
    "            #print(\"2nd if loop\",i)\n",
    "            model['W'+str(i)] = np.random.randn(hidden_nodes, output_dim) / np.sqrt(hidden_nodes)\n",
    "            model['b'+str(i)] =  np.zeros((1, output_dim))\n",
    "        else:\n",
    "            #print(\"else loop\",i)\n",
    "            model['W'+str(i)] =  np.random.randn(hidden_nodes, hidden_nodes) / np.sqrt(hidden_nodes) \n",
    "            model['b'+str(i)] =  np.zeros((1, hidden_nodes))\n",
    "    \n",
    "        \n",
    "    return model\n",
    "\n",
    "def feed_forward(neural_layer,model, x):\n",
    "    z={}\n",
    "    a={}\n",
    "    for i in range(1,neural_layer+1):\n",
    "        \n",
    "        # Forward propagation for layer 1\n",
    "        if i==1:\n",
    "            continue\n",
    "        # Forward propagation for layer 2\n",
    "        elif i==2:\n",
    "            z[i] = x.dot(model['W'+str(i-1)]) + model['b'+str(i-1)]\n",
    "            a[i] = sigmoid(z[i])\n",
    "            #print(\"z2:\",z2)\n",
    "        # Forward propagation for other layer  \n",
    "        else:\n",
    "            z[i] = a[i-1].dot(model['W'+str(i-1)]) + model['b'+str(i-1)]\n",
    "            a[i] = sigmoid(z[i])\n",
    "            #print(\"z3:\",z3)\n",
    "    return a\n",
    "\n",
    "def backprop(neural_layer,x,y,model,a,tri_Delta):\n",
    "    #Lower delta error\n",
    "    delt = {}\n",
    "    for i in range(neural_layer,1,-1):\n",
    "        #output layer  error \n",
    "        if i==neural_layer:\n",
    "            delt[i] = a[i] - y\n",
    "            \n",
    "            tri_Delta['b'+str(i-1)] += np.sum(delt[i], axis=0, keepdims=True)\n",
    "            tri_Delta['W'+str(i-1)] += (a[i-1].T).dot(delt[i])\n",
    "            #print(\"db2:\",db2)\n",
    "            #print(\"dW2:\",dW2)\n",
    "             \n",
    "        #Error in second layer \n",
    "        elif i==2:\n",
    "            delt[i] = np.multiply(delt[i+1].dot(model['W'+str(i)].T),(a[i]*(1-a[i])))\n",
    "            #print(\"del2:\",del2)\n",
    "            tri_Delta['b'+str(i-1)] += np.sum(delt[i], axis=0, keepdims=True)\n",
    "            tri_Delta['W'+str(i-1)] += np.dot(x.T, delt[i])\n",
    "        #Hidden layer error\n",
    "        else:\n",
    "            delt[i] = np.multiply(delt[i+1].dot(model['W'+str(i)].T),(a[i]*(1-a[i])))\n",
    "            #print(\"del2:\",del2)\n",
    "            tri_Delta['b'+str(i-1)] += np.sum(delt[i], axis=0, keepdims=True)\n",
    "            tri_Delta['W'+str(i-1)] += np.dot(a[i-1].T, delt[i])\n",
    "    #print(\"delt:\",delt)\n",
    "    return tri_Delta\n",
    "\n",
    "def calculate_loss(neural_layer,N,model,a,y_true,sum_cost):\n",
    "    #sum_cost += np.sum((a[neural_layer]-y_true)**2)\n",
    "    \n",
    "    \n",
    "    sum_cost +=np.sum((y_true*np.log(a[neural_layer]))+((1-y_true)*np.log(1-a[neural_layer])))\n",
    "    #print(\"sum_cost\",sum_cost)\n",
    "    \n",
    "    return sum_cost\n",
    "\n",
    "def train(neural_layer,N,model, X_train, y_train,input_dim, reg_lambda, learning_rate,hidden_nodes):\n",
    "    # Batch gradient descent\n",
    "    done = False\n",
    "    previous_loss = float('inf')\n",
    "    iterations = 0\n",
    "    \n",
    "    losses = []\n",
    "    #while done == False:  #comment out while performance testing\n",
    "    while iterations < 500:\n",
    "        scost=0\n",
    "        tri_Delta={}\n",
    "        for i in range(neural_layer):\n",
    "            if i==0:\n",
    "                continue\n",
    "            elif i==1:\n",
    "                #print(\"1st elif loop\",i)\n",
    "                tri_Delta['W'+str(i)] =  np.zeros((input_dim, hidden_nodes)) \n",
    "                tri_Delta['b'+str(i)] =  np.zeros((1, hidden_nodes))\n",
    "            elif i==neural_layer-1:\n",
    "                #print(\"2nd if loop\",i)\n",
    "                tri_Delta['W'+str(i)] = np.zeros((hidden_nodes, output_dim))\n",
    "                tri_Delta['b'+str(i)] =  np.zeros((1, output_dim))\n",
    "            else:\n",
    "                #print(\"else loop\",i)\n",
    "                tri_Delta['W'+str(i)] =  np.zeros((hidden_nodes, hidden_nodes)) \n",
    "                tri_Delta['b'+str(i)] =  np.zeros((1, hidden_nodes))\n",
    "            \n",
    "        \n",
    "        for row in zip(X_train, y_train):\n",
    "            #feed forward\n",
    "            a = feed_forward(neural_layer,model, row[0][None,:])\n",
    "           \n",
    "            tri_Delta = backprop(neural_layer,row[0][None,:],row[1][None,:],model,a,tri_Delta)\n",
    "            \n",
    "            #cost\n",
    "            cost = calculate_loss(neural_layer,N,model, a,row[1][None,:], scost)\n",
    "            \n",
    "        #update weights and biases\n",
    "        for i in range(1,neural_layer):\n",
    "            model['W'+str(i)]-= learning_rate*((tri_Delta['W'+str(i)]/N) + (reg_lambda/N)* model['W'+str(i)])\n",
    "            model['b'+str(i)]-= learning_rate*(tri_Delta['b'+str(i)]/N) \n",
    "        sc=0\n",
    "        for nl in range(1,n_layer):\n",
    "            sc+= np.sum(np.square(model['W'+str(nl)])) \n",
    "        loss = (-1/N)*cost+(reg_lambda/2*N)*sc\n",
    "        #print(\"cost:\",cost,\"loss:\",loss)\n",
    "        losses.append(loss)\n",
    "        if iterations%100==0:\n",
    "            print (\"Loss after iteration %i: %f\" %(iterations, loss))  #uncomment once testing finished, return mod val to 1000\n",
    "        if ( previous_loss-loss) < 0.000001:\n",
    "            done = True\n",
    "            #print(\"convergence i:\",iterations,previous_loss-loss) \n",
    "            #break\n",
    "        previous_loss = loss\n",
    "        iterations += 1\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sdataset = pd.read_csv('BSOM_DataSet_for_HW3.csv')\n",
    "X = sdataset.loc[:,['all_mcqs_avg_n20','all_NBME_avg_n4','CBSE_01','CBSE_02']].values\n",
    "X1 = sdataset.loc[:,['all_mcqs_avg_n20','all_NBME_avg_n4','CBSE_01','CBSE_02','STEP_1']].values\n",
    "X2 = sdataset.loc[:,['all_mcqs_avg_n20','all_NBME_avg_n4','CBSE_01','CBSE_02','SA_IRAT_AVG_07','STEP_1']].values\n",
    "y = sdataset.loc[:,['LEVEL']].values\n",
    "\n",
    "#Feature Scaling using Mean normalization \n",
    "mean_norm_X = (X-np.mean(X,axis=0))/(np.max(X,axis=0)-np.min(X,axis=0))\n",
    "mean_norm_X1 = (X1-np.mean(X1,axis=0))/(np.max(X1,axis=0)-np.min(X1,axis=0))\n",
    "mean_norm_X2 = (X1-np.mean(X1,axis=0))/(np.max(X1,axis=0)-np.min(X1,axis=0))\n",
    "#One vs all y_train\n",
    "concat=[]\n",
    "for i in np.unique(y):\n",
    "    one_vs_all_y=np.where(y==i,1,0)\n",
    "    concat.extend(list(zip(*one_vs_all_y)))\n",
    "actual_y= np.asarray(concat).T \n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(mean_norm_X, actual_y, test_size = 1/3)\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(mean_norm_X1, actual_y, test_size = 1/3)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(mean_norm_X2, actual_y, test_size = 1/3)\n",
    "N,input_features = X_train.shape \n",
    "N,input_features1 = X1_train.shape\n",
    "N,input_features2 = X2_train.shape\n",
    "# output layer dimensionality \n",
    "output_dim = len(np.unique(y)) \n",
    "# learning rate for gradient descent\n",
    "learning_rate = 0.6\n",
    "hidden_nodes=5\n",
    "reg_lambda = 0.001 # regularization strength\n",
    "n_layer=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fscore(y_true, y_pred):\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')  \n",
    "    print(\"F1 macro :\" ,f1_macro)\n",
    "    f1_micro  = f1_score(y_test, y_pred, average='micro')  \n",
    "    print(\"F1 micro :\" ,f1_micro)\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')  \n",
    "    print(\"F1 weighted :\" ,f1_weighted)\n",
    "    f1 = f1_score(y_test, y_pred, average=None)\n",
    "    print(\"F1 score :\" ,f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0: 0.264604\n",
      "Loss after iteration 100: 0.717414\n",
      "Loss after iteration 200: 2.447373\n",
      "Loss after iteration 300: 3.822840\n",
      "Loss after iteration 400: 4.903479\n",
      "y_true [2, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 2, 1, 1, 2, 3, 0, 1, 1, 1, 2, 1, 1, 2, 3, 1, 0, 2, 2, 0, 1, 1, 1, 1, 1, 0, 3, 1, 1]\n",
      "y_pred [2, 1, 0, 0, 2, 0, 0, 1, 1, 0, 0, 2, 1, 0, 2, 2, 0, 0, 1, 1, 2, 0, 2, 2, 2, 1, 0, 2, 1, 0, 0, 1, 0, 1, 0, 0, 2, 1, 2]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.50      1.00      0.67         8\n",
      "          B       0.91      0.48      0.62        21\n",
      "          C       0.50      0.86      0.63         7\n",
      "          D       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.68      0.62      0.59        39\n",
      "\n",
      "confusion matrix: [[ 8  0  0  0]\n",
      " [ 8 10  3  0]\n",
      " [ 0  1  6  0]\n",
      " [ 0  0  3  0]]\n",
      "Accuracy: 0.6153846153846154\n",
      "F1 macro : 0.4808114035087719\n",
      "F1 micro : 0.6153846153846154\n",
      "F1 weighted : 0.586650922177238\n",
      "F1 score : [0.66666667 0.625      0.63157895 0.        ]\n",
      "ROC AUC score 0.7290266577060932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = build_model(X_train,n_layer,input_features,hidden_nodes,output_dim)\n",
    "model, losses = train(n_layer,N,model,X_train, y_train,input_features, reg_lambda, learning_rate,hidden_nodes)\n",
    "\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for row in zip(X_test, y_test):\n",
    "    a = feed_forward(n_layer,model, row[0][None,:])\n",
    "    y_pred.append(np.argmax(a[n_layer]))\n",
    "    y_true.append(np.argmax(row[1][None,:]))\n",
    "print(\"y_true\",y_true)\n",
    "print(\"y_pred\",y_pred)\n",
    "print(classification_report(y_true, y_pred,target_names=['A', 'B', 'C','D']))   \n",
    "print(\"confusion matrix:\",confusion_matrix(y_true, y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_true, y_pred))\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_true)\n",
    "y_t= lb.transform(y_true)\n",
    "y_p = lb.transform(y_pred)\n",
    "fscore(y_t,y_p)\n",
    "print(\"ROC AUC score\",metrics.roc_auc_score(y_t,y_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3a Adding one feature and 3c metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0: 0.415760\n",
      "Loss after iteration 100: 0.927066\n",
      "Loss after iteration 200: 2.811294\n",
      "Loss after iteration 300: 4.549292\n",
      "Loss after iteration 400: 6.258585\n",
      "y_true [3, 2, 0, 3, 2, 3, 1, 0, 0, 2, 1, 1, 2, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 1, 1, 2, 0, 0, 1, 1, 2, 0, 0, 1, 2, 2, 0, 2]\n",
      "y_pred [2, 1, 0, 2, 1, 2, 1, 0, 0, 2, 1, 1, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 0, 1, 2, 0, 0, 1, 1, 2, 0, 0, 1, 2, 2, 0, 2]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.92      0.92      0.92        13\n",
      "          B       0.80      0.92      0.86        13\n",
      "          C       0.73      0.80      0.76        10\n",
      "          D       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.76      0.82      0.79        39\n",
      "\n",
      "confusion matrix: [[12  1  0  0]\n",
      " [ 1 12  0  0]\n",
      " [ 0  2  8  0]\n",
      " [ 0  0  3  0]]\n",
      "Accuracy: 0.8205128205128205\n",
      "ROC AUC score 0.798607427055703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = build_model(X1_train,n_layer,input_features1,hidden_nodes,output_dim)\n",
    "model, losses = train(n_layer,N,model,X1_train, y1_train,input_features1, reg_lambda, learning_rate,hidden_nodes)\n",
    "\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for row in zip(X1_test, y1_test):\n",
    "    a = feed_forward(n_layer,model, row[0][None,:])\n",
    "    y_pred.append(np.argmax(a[n_layer]))\n",
    "    y_true.append(np.argmax(row[1][None,:]))\n",
    "print(\"y_true\",y_true)\n",
    "print(\"y_pred\",y_pred)\n",
    "print(classification_report(y_true, y_pred,target_names=['A', 'B', 'C','D']))   \n",
    "print(\"confusion matrix:\",confusion_matrix(y_true, y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_true, y_pred))\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_true)\n",
    "y_t= lb.transform(y_true)\n",
    "y_p = lb.transform(y_pred)\n",
    "\n",
    "print(\"ROC AUC score\",metrics.roc_auc_score(y_t,y_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3b Adding another features and 3c metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0: 0.392501\n",
      "Loss after iteration 100: 1.210299\n",
      "Loss after iteration 200: 3.005351\n",
      "Loss after iteration 300: 4.391723\n",
      "Loss after iteration 400: 5.829362\n",
      "y_true [2, 0, 2, 0, 2, 3, 2, 0, 1, 1, 0, 2, 0, 0, 1, 1, 0, 0, 1, 1, 2, 0, 1, 1, 1, 0, 1, 0, 1, 2, 1, 0, 0, 1, 2, 0, 3, 1, 0]\n",
      "y_pred [1, 0, 1, 0, 2, 2, 1, 0, 1, 2, 0, 2, 1, 0, 1, 1, 0, 0, 1, 2, 2, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 2, 1, 0, 2, 1, 0]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.93      0.93      0.93        15\n",
      "          B       0.62      0.71      0.67        14\n",
      "          C       0.38      0.38      0.38         8\n",
      "          D       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.66      0.69      0.68        39\n",
      "\n",
      "confusion matrix: [[14  1  0  0]\n",
      " [ 1 10  3  0]\n",
      " [ 0  5  3  0]\n",
      " [ 0  0  2  0]]\n",
      "Accuracy: 0.6923076923076923\n",
      "ROC AUC score 0.6974577572964671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = build_model(X2_train,n_layer,input_features2,hidden_nodes,output_dim)\n",
    "model, losses = train(n_layer,N,model,X2_train, y2_train,input_features2, reg_lambda, learning_rate,hidden_nodes)\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for row in zip(X2_test, y2_test):\n",
    "    a = feed_forward(n_layer,model, row[0][None,:])\n",
    "    y_pred.append(np.argmax(a[n_layer]))\n",
    "    y_true.append(np.argmax(row[1][None,:]))\n",
    "print(\"y_true\",y_true)\n",
    "print(\"y_pred\",y_pred)\n",
    "print(classification_report(y_true, y_pred,target_names=['A', 'B', 'C','D']))   \n",
    "print(\"confusion matrix:\",confusion_matrix(y_true, y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_true, y_pred))\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y2_test)\n",
    "y_t= lb.transform(y_true)\n",
    "y_p = lb.transform(y_pred)\n",
    "\n",
    "print(\"ROC AUC score\",metrics.roc_auc_score(y_t,y_p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
