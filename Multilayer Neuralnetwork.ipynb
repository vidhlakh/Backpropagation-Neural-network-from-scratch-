{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return  1/(1+np.exp(-z))\n",
    "\n",
    "def build_model(X,neural_layer,input_dim,hidden_nodes,output_dim):\n",
    "    model = {}\n",
    "    for i in range(neural_layer):\n",
    "        if i==0:\n",
    "            continue\n",
    "        elif i==1:\n",
    "            #print(\"1st elif loop\",i)\n",
    "            model['W'+str(i)] =  np.random.randn(input_dim, hidden_nodes) / np.sqrt(input_dim) \n",
    "            model['b'+str(i)] =  np.zeros((1, hidden_nodes))\n",
    "        elif i==neural_layer-1:\n",
    "            #print(\"2nd if loop\",i)\n",
    "            model['W'+str(i)] = np.random.randn(hidden_nodes, output_dim) / np.sqrt(hidden_nodes)\n",
    "            model['b'+str(i)] =  np.zeros((1, output_dim))\n",
    "        else:\n",
    "            #print(\"else loop\",i)\n",
    "            model['W'+str(i)] =  np.random.randn(hidden_nodes, hidden_nodes) / np.sqrt(hidden_nodes) \n",
    "            model['b'+str(i)] =  np.zeros((1, hidden_nodes))\n",
    "    \n",
    "        \n",
    "    return model\n",
    "\n",
    "def feed_forward(neural_layer,model, x):\n",
    "    z={}\n",
    "    a={}\n",
    "    for i in range(1,neural_layer+1):\n",
    "        \n",
    "        # Forward propagation for layer 1\n",
    "        if i==1:\n",
    "            continue\n",
    "        # Forward propagation for layer 2\n",
    "        elif i==2:\n",
    "            z[i] = x.dot(model['W'+str(i-1)]) + model['b'+str(i-1)]\n",
    "            a[i] = sigmoid(z[i])\n",
    "            #print(\"z2:\",z2)\n",
    "        # Forward propagation for other layer  \n",
    "        else:\n",
    "            z[i] = a[i-1].dot(model['W'+str(i-1)]) + model['b'+str(i-1)]\n",
    "            a[i] = sigmoid(z[i])\n",
    "            #print(\"z3:\",z3)\n",
    "    return a\n",
    "\n",
    "def backprop(neural_layer,x,y,model,a,tri_Delta):\n",
    "    #Lower delta error\n",
    "    delt = {}\n",
    "    for i in range(neural_layer,1,-1):\n",
    "        #output layer  error \n",
    "        if i==neural_layer:\n",
    "            delt[i] = a[i] - y\n",
    "            \n",
    "            tri_Delta['b'+str(i-1)] += np.sum(delt[i], axis=0, keepdims=True)\n",
    "            tri_Delta['W'+str(i-1)] += (a[i-1].T).dot(delt[i])\n",
    "            #print(\"db2:\",db2)\n",
    "            #print(\"dW2:\",dW2)\n",
    "             \n",
    "        #Error in second layer \n",
    "        elif i==2:\n",
    "            delt[i] = np.multiply(delt[i+1].dot(model['W'+str(i)].T),(a[i]*(1-a[i])))\n",
    "            #print(\"del2:\",del2)\n",
    "            tri_Delta['b'+str(i-1)] += np.sum(delt[i], axis=0, keepdims=True)\n",
    "            tri_Delta['W'+str(i-1)] += np.dot(x.T, delt[i])\n",
    "        #Hidden layer error\n",
    "        else:\n",
    "            delt[i] = np.multiply(delt[i+1].dot(model['W'+str(i)].T),(a[i]*(1-a[i])))\n",
    "            #print(\"del2:\",del2)\n",
    "            tri_Delta['b'+str(i-1)] += np.sum(delt[i], axis=0, keepdims=True)\n",
    "            tri_Delta['W'+str(i-1)] += np.dot(a[i-1].T, delt[i])\n",
    "    #print(\"delt:\",delt)\n",
    "    return tri_Delta\n",
    "\n",
    "def calculate_loss(neural_layer,N,model,a,y_true,sum_cost):\n",
    "    #sum_cost += np.sum((a[neural_layer]-y_true)**2) \n",
    "    sum_cost +=np.sum((y_true*np.log(a[neural_layer]))+((1-y_true)*np.log(1-a[neural_layer])))\n",
    "    #print(\"sum_cost\",sum_cost)\n",
    "    \n",
    "    return sum_cost\n",
    "\n",
    "def train(neural_layer,N,model, X_train, y_train, reg_lambda, learning_rate,hidden_nodes):\n",
    "    # Batch gradient descent\n",
    "    done = False\n",
    "    previous_loss = float('inf')\n",
    "    iterations = 0\n",
    "    \n",
    "    losses = []\n",
    "    #while done == False:  #comment out while performance testing\n",
    "    while iterations < 200:\n",
    "        scost=0\n",
    "        tri_Delta={}\n",
    "        for i in range(neural_layer):\n",
    "            if i==0:\n",
    "                continue\n",
    "            elif i==1:\n",
    "                #print(\"1st elif loop\",i)\n",
    "                tri_Delta['W'+str(i)] =  np.zeros((input_dim, hidden_nodes)) \n",
    "                tri_Delta['b'+str(i)] =  np.zeros((1, hidden_nodes))\n",
    "            elif i==neural_layer-1:\n",
    "                #print(\"2nd if loop\",i)\n",
    "                tri_Delta['W'+str(i)] = np.zeros((hidden_nodes, output_dim))\n",
    "                tri_Delta['b'+str(i)] =  np.zeros((1, output_dim))\n",
    "            else:\n",
    "                #print(\"else loop\",i)\n",
    "                tri_Delta['W'+str(i)] =  np.zeros((hidden_nodes, hidden_nodes)) \n",
    "                tri_Delta['b'+str(i)] =  np.zeros((1, hidden_nodes))\n",
    "            \n",
    "        \n",
    "        for row in zip(X_train, y_train):\n",
    "            #feed forward\n",
    "            a = feed_forward(neural_layer,model, row[0][None,:])\n",
    "           \n",
    "            tri_Delta = backprop(neural_layer,row[0][None,:],row[1][None,:],model,a,tri_Delta)\n",
    "            \n",
    "            #cost\n",
    "            cost = calculate_loss(neural_layer,N,model, a,row[1][None,:], scost)\n",
    "            \n",
    "        #update weights and biases\n",
    "        for i in range(1,neural_layer):\n",
    "            model['W'+str(i)]-= learning_rate*((tri_Delta['W'+str(i)]/N) + (reg_lambda/N)* model['W'+str(i)])\n",
    "            model['b'+str(i)]-= learning_rate*(tri_Delta['b'+str(i)]/N) \n",
    "        loss = (-1/N)*cost\n",
    "        #print(\"cost:\",cost,\"loss:\",loss)\n",
    "        losses.append(loss)\n",
    "        if iterations%100==0:\n",
    "            print (\"Loss after iteration %i: %f\" %(i, loss))  #uncomment once testing finished, return mod val to 1000\n",
    "        if ( previous_loss-loss) < 0.000001:\n",
    "            done = True\n",
    "            #print(\"convergence i:\",iterations,previous_loss-loss) \n",
    "            #break\n",
    "        previous_loss = loss\n",
    "        iterations += 1\n",
    "    return model, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(222)\n",
    "sdataset = pd.read_csv('BSOM_DataSet_for_HW3.csv')\n",
    "X = sdataset.loc[:,['all_mcqs_avg_n20','all_NBME_avg_n4','CBSE_01','CBSE_02']].values\n",
    "y = sdataset.loc[:,['LEVEL']].values\n",
    "\n",
    "#Feature Scaling using Mean normalization \n",
    "mean_norm_X = (X-np.mean(X,axis=0))/(np.max(X,axis=0)-np.min(X,axis=0))\n",
    "#One vs all y_train\n",
    "concat=[]\n",
    "for i in np.unique(y):\n",
    "    one_vs_all_y=np.where(y==i,1,0)\n",
    "    concat.extend(list(zip(*one_vs_all_y)))\n",
    "actual_y= np.asarray(concat).T \n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(mean_norm_X, actual_y, test_size = 1/3)\n",
    "\n",
    "N,input_dim = X_train.shape \n",
    "# output layer dimensionality \n",
    "output_dim = len(np.unique(y)) \n",
    "# learning rate for gradient descent\n",
    "learning_rate = 0.6\n",
    "#hidden nodes for all layers \n",
    "hidden_nodes=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fscore(y_true, y_pred):\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')  \n",
    "    print(\"F1 macro :\" ,f1_macro)\n",
    "    f1_micro  = f1_score(y_test, y_pred, average='micro')  \n",
    "    print(\"F1 micro :\" ,f1_micro)\n",
    "    f1_weighted = f1_score(y_test, y_pred, average='weighted')  \n",
    "    print(\"F1 weighted :\" ,f1_weighted)\n",
    "    f1 = f1_score(y_test, y_pred, average=None)\n",
    "    print(\"F1 score :\" ,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For NEURAL LAYER : 3\n",
      "Loss after iteration 2: 0.040607\n",
      "Loss after iteration 2: 0.019092\n",
      "y_true [0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 1, 3, 1, 2, 1, 3, 0, 0, 1, 2, 1, 1, 2, 0, 0, 3, 0]\n",
      "y_pred [0, 1, 1, 0, 2, 0, 1, 1, 1, 1, 2, 1, 0, 1, 2, 0, 2, 0, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 0, 2, 2, 2, 1, 2, 0, 0, 1, 1]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.89      0.67      0.76        12\n",
      "          B       0.59      0.67      0.62        15\n",
      "          C       0.62      0.89      0.73         9\n",
      "          D       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.64      0.67      0.64        39\n",
      "\n",
      "confusion matrix: [[ 8  4  0  0]\n",
      " [ 1 10  4  0]\n",
      " [ 0  1  8  0]\n",
      " [ 0  2  1  0]]\n",
      "Accuracy: 0.6666666666666666\n",
      "ROC AUC score 0.7158564814814815\n",
      "F1 macro : 0.5285443722943723\n",
      "F1 micro : 0.6666666666666666\n",
      "F1 weighted : 0.6426490176490177\n",
      "F1 score : [0.76190476 0.625      0.72727273 0.        ]\n",
      "For NEURAL LAYER : 4\n",
      "Loss after iteration 3: 0.037748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 3: 0.019512\n",
      "y_true [0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 1, 3, 1, 2, 1, 3, 0, 0, 1, 2, 1, 1, 2, 0, 0, 3, 0]\n",
      "y_pred [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.00      0.00      0.00        12\n",
      "          B       0.38      1.00      0.56        15\n",
      "          C       0.00      0.00      0.00         9\n",
      "          D       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.15      0.38      0.21        39\n",
      "\n",
      "confusion matrix: [[ 0 12  0  0]\n",
      " [ 0 15  0  0]\n",
      " [ 0  9  0  0]\n",
      " [ 0  3  0  0]]\n",
      "Accuracy: 0.38461538461538464\n",
      "ROC AUC score 0.5\n",
      "F1 macro : 0.1388888888888889\n",
      "F1 micro : 0.38461538461538464\n",
      "F1 weighted : 0.2136752136752137\n",
      "F1 score : [0.         0.55555556 0.         0.        ]\n",
      "For NEURAL LAYER : 5\n",
      "Loss after iteration 4: 0.048274\n",
      "Loss after iteration 4: 0.019007\n",
      "y_true [0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 1, 3, 1, 2, 1, 3, 0, 0, 1, 2, 1, 1, 2, 0, 0, 3, 0]\n",
      "y_pred [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.00      0.00      0.00        12\n",
      "          B       0.38      1.00      0.56        15\n",
      "          C       0.00      0.00      0.00         9\n",
      "          D       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.15      0.38      0.21        39\n",
      "\n",
      "confusion matrix: [[ 0 12  0  0]\n",
      " [ 0 15  0  0]\n",
      " [ 0  9  0  0]\n",
      " [ 0  3  0  0]]\n",
      "Accuracy: 0.38461538461538464\n",
      "ROC AUC score 0.5\n",
      "F1 macro : 0.1388888888888889\n",
      "F1 micro : 0.38461538461538464\n",
      "F1 weighted : 0.2136752136752137\n",
      "F1 score : [0.         0.55555556 0.         0.        ]\n",
      "For NEURAL LAYER : 6\n",
      "Loss after iteration 5: 0.031068\n",
      "Loss after iteration 5: 0.018978\n",
      "y_true [0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 1, 3, 1, 2, 1, 3, 0, 0, 1, 2, 1, 1, 2, 0, 0, 3, 0]\n",
      "y_pred [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.00      0.00      0.00        12\n",
      "          B       0.38      1.00      0.56        15\n",
      "          C       0.00      0.00      0.00         9\n",
      "          D       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.15      0.38      0.21        39\n",
      "\n",
      "confusion matrix: [[ 0 12  0  0]\n",
      " [ 0 15  0  0]\n",
      " [ 0  9  0  0]\n",
      " [ 0  3  0  0]]\n",
      "Accuracy: 0.38461538461538464\n",
      "ROC AUC score 0.5\n",
      "F1 macro : 0.1388888888888889\n",
      "F1 micro : 0.38461538461538464\n",
      "F1 weighted : 0.2136752136752137\n",
      "F1 score : [0.         0.55555556 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_layers = [3,4,5,6]\n",
    "reg_lambda = 0 # regularization strength\n",
    "for n_layer in n_layers:\n",
    "    print(\"For NEURAL LAYER :\",n_layer)\n",
    "    model = build_model(X_train,n_layer,input_dim,hidden_nodes,output_dim)\n",
    "    model, losses = train(n_layer,N,model,X_train, y_train, reg_lambda, learning_rate,hidden_nodes)\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for row in zip(X_test, y_test):\n",
    "        a = feed_forward(n_layer,model, row[0][None,:])\n",
    "        y_pred.append(np.argmax(a[n_layer]))\n",
    "        y_true.append(np.argmax(row[1][None,:]))\n",
    "    print(\"y_true\",y_true)\n",
    "    print(\"y_pred\",y_pred)\n",
    "    print(classification_report(y_true, y_pred,target_names=['A', 'B', 'C','D']))   \n",
    "    print(\"confusion matrix:\",confusion_matrix(y_true, y_pred))\n",
    "    print(\"Accuracy:\",accuracy_score(y_true, y_pred))\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_true)\n",
    "    y_t= lb.transform(y_true)\n",
    "    y_p = lb.transform(y_pred)\n",
    "\n",
    "    print(\"ROC AUC score\",metrics.roc_auc_score(y_t,y_p))\n",
    "    fscore(y_t,y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
